{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling process for #WeRateDogs twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Goal:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data wrangling involves various steps in getting the data in it's best possible form for analysis and vizualization for insights since raw data comes through as dirty data.\n",
    "This whole process involves 3 major steps.\n",
    "- Gather\n",
    "- Assess \n",
    "- Cleaning\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This required for various libraries to be imported which included:\n",
    "- Numpy\n",
    "- Pandas\n",
    "- Requests\n",
    "- Os\n",
    "- Tweepy\n",
    "- Seaborn\n",
    "- Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering:\n",
    "This step involves acquiring and collecting the data required for the analysis. For this case study, the data source comes off the back of Twitter specifically using an API to get raw data off of the (@WeRateDogs) twitter account which rates various breeds of dogs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data:\n",
    "##### Enhanced Twitter Archive\n",
    "The WeRateDogs Twitter archive contains basic tweet data in its current state at 2356 rows. The file used was the [twitter-archive-enhanced.csv] file. This was imported using pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Image Predictions File\n",
    "This file was built off a neural network and is used to classify the dog breeds. The file name [image-predictions.tsv] was imported using pandas but specifically seperated by tabs. This was picked off using the provided url and opened said url through the requests Library. Opening this should provide a 200 response which means it has been written to the  [image-predictions.tsv] file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Additional Data via the Twitter API\n",
    " This file is based off of a twitter archive of the (@WeRateDogs) profile and the tweets made by them within a specific time. Using the Tweepy Library to query the Twitter's API, This can be done by creating a twitter developer's account, set up some code to create an API object, Query various Tweet Id's and write its JSON data to a text file [tweet-json.txt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Data:\n",
    "This part of the process involves programmaticaly and visually looking through the data to assess and find various quality and Tidiness issues. \n",
    "\n",
    "\n",
    "##### Programmaticaly:\n",
    "This involves using various methods from nunique(), info(), value_counts() and other methods of code to break down each file specifically looking for Issues.\n",
    "\n",
    "##### Visually:\n",
    "This involves looking at each of the 3 dataframes from a human standpoint, scrolling through the data to find any quality or untidy data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data:\n",
    "Assesing the data, shown below are the various quality issues as well as the untidiness found across the 3 datasets. All three were merged to create a singular data set containing as much cleaned information as possible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality issues\n",
    "1. Null values represented as None in the dog stage category columns in tweet_dogs. The None values were replaced with ('') and eventually replaced with Nan.\n",
    "\n",
    "\n",
    "2. Missing values from the in_reply_to status, in_reply_to user_id columns. These were removed using the .drop() method. \n",
    "\n",
    "\n",
    "3. Timestamp column not in datetime format. Converted to datetime using astype() and importing datetime\n",
    "\n",
    "\n",
    "4. Tweet Id is int format rather than a string in tweet-dogs dataframe. Converted using astype(str)\n",
    "\n",
    "\n",
    "5. retweeted status_id, retweeted_status_user_id,retweeted_status_timestamp, are retweeted values and won't be used in the analysis. These were removed using the .drop() method.\n",
    "\n",
    "\n",
    "6. retweeted status_id, retweeted_status_user_id,retweeted_status_timestamp & expanded urls have missing values. These were removed using the .drop() method.\n",
    "\n",
    "\n",
    "7. Follower_count & Friend_count in Json_tweets have repetitve values. These were removed using the .drop() method.\n",
    "\n",
    "\n",
    "8. Tweet_Id column in image-predictions is an int64 rather than a string. Converted using astype(str)\n",
    "\n",
    "\n",
    "9. The Id column in json_tweets is the same asa tweet_Id in other dataframes. Changing the column header using the .replace method\n",
    "\n",
    "\n",
    "10. Tweet_Id column in json-tweets is an int64 rather than a string. Converted using astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidiness issues\n",
    "1. Having the dog stage(4 variables in 4 columns) rather than one column in tweet_dogs. By adding the various columns into one column ('stage') and then dropping the 4 columns using the .drop() method.\n",
    "\n",
    "\n",
    "2. Merge all 3 tables (tweet_dogs, image_predictions, json_tweets). These were merged using the .merge() method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing the Data\n",
    "After merging the data, it was saved as \n",
    "##### twitter_archive_master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "This was a quite a long process and at times stuck for periods of time. It required constant searches and explantions. I do wish to to do this again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
